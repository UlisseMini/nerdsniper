{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import time\n",
    "import itertools\n",
    "import emoji"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "EMOJI_SET = set(emoji.UNICODE_EMOJI.keys())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "%matplotlib notebook"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.7449633901688092\n"
     ]
    }
   ],
   "source": [
    "F = pd.read_csv('results/female.csv')\n",
    "M = pd.read_csv('results/male.csv')\n",
    "print(len(F)/(len(F) + len(M)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Fix gender distributions in data. This is silly; batching might work better.\n",
    "s = min(len(F), len(M))\n",
    "\n",
    "F = F[:s]\n",
    "M = M[:s]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "metadata": {},
   "outputs": [],
   "source": [
    "def tokenize(s):\n",
    "    tokens = []\n",
    "        \n",
    "    s = s.strip().lower()\n",
    "    \n",
    "    s = s.replace('she/her', '')\n",
    "    s = s.replace('he/him', '')\n",
    "    \n",
    "    for char in ',.:();|':\n",
    "        s = s.replace(char, '')\n",
    "        \n",
    "    for char in '/\\n':\n",
    "        s = s.replace(char, ' ')\n",
    "\n",
    "\n",
    "    \n",
    "    ignore_words = {'a', 'and', 'it', }\n",
    "    \n",
    "    tokens += list(filter(\n",
    "        lambda t: t != '' and t not in ignore_words,\n",
    "        map(str.strip, s.split(' '))\n",
    "    ))\n",
    "    \n",
    "    \n",
    "    \n",
    "    return tokens\n",
    "\n",
    "def populate(token_freq_dict, df):\n",
    "    for desc in df.description:\n",
    "        for token in tokenize(desc):\n",
    "            token_freq_dict[token] = (token_freq_dict.get(token) or 0) + 1\n",
    "                \n",
    "                \n",
    "    return token_freq_dict"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "metadata": {},
   "outputs": [],
   "source": [
    "token_freqs_F = populate({}, F)\n",
    "token_freqs_M = populate({}, M)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "metadata": {},
   "outputs": [],
   "source": [
    "def delete(d, k):\n",
    "    try:\n",
    "        del d[k]\n",
    "    except KeyError:\n",
    "        pass\n",
    "\n",
    "# Only keep words with more then 1000 total occurences to avoid skewing\n",
    "for token in set([*token_freqs_F.keys(), *token_freqs_M.keys()]):\n",
    "    total = (token_freqs_F.get(token) or 0) + (token_freqs_M.get(token) or 0)\n",
    "    if total < 100:\n",
    "        delete(token_freqs_F, token)\n",
    "        delete(token_freqs_M, token)\n",
    "        #tf_F_small[token] = token_freqs_F.get(token) or 0\n",
    "        #tf_M_small[token] = token_freqs_M.get(token) or 0"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 60,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "min F 1\n",
      "len F 1991\n",
      "min M 3\n",
      "len M 1992\n",
      "535021\n",
      "658181\n"
     ]
    }
   ],
   "source": [
    "print('min F', min(token_freqs_F.values()))\n",
    "print('len F', len(token_freqs_F))\n",
    "print('min M', min(token_freqs_M.values()))\n",
    "print('len M', len(token_freqs_M))\n",
    "\n",
    "\n",
    "tokens_in_F = sum(token_freqs_F.values())\n",
    "tokens_in_M = sum(token_freqs_M.values())\n",
    "\n",
    "print(tokens_in_F)\n",
    "print(tokens_in_M)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 61,
   "metadata": {},
   "outputs": [],
   "source": [
    "def P_female_given(tokens):\n",
    "    P_H = 0.5\n",
    "    \n",
    "    for token in tokens:\n",
    "        if token_freqs_F.get(token) is None or token_freqs_M.get(token) is None:\n",
    "            continue\n",
    "        \n",
    "        # P(H)P(E|H) / P(H)P(E|H) + P(-H)P(E|-H)\n",
    "        P_E_GIVEN_H      = token_freqs_F[token] / tokens_in_F\n",
    "        P_E_GIVEN_NULL_H = token_freqs_M[token] / tokens_in_M\n",
    "\n",
    "        P_NULL_H = 1 - P_H\n",
    "        P_H = (P_H*P_E_GIVEN_H) / (P_H*P_E_GIVEN_H + P_NULL_H*P_E_GIVEN_NULL_H)\n",
    "    \n",
    "    return P_H"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 62,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'correct': 105880,\n",
       " 'correct_w': 101571.91223332938,\n",
       " 'no_tok': 9218,\n",
       " 'took': 1.815723261614039,\n",
       " 'accuracy': 0.704626523984454}"
      ]
     },
     "execution_count": 62,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "R = {\n",
    "    'correct': 0,\n",
    "    'correct_w': 0, # weighted correct\n",
    "    'no_tok': 0,\n",
    "    'took': 0,\n",
    "}\n",
    "\n",
    "def do_it(iterator, gender, R):\n",
    "    for bio in iterator:\n",
    "        start = time.monotonic()\n",
    "        tokens = tokenize(bio)\n",
    "        P_female = P_female_given(tokens)\n",
    "        R['took'] += time.monotonic() - start\n",
    "\n",
    "        R['no_tok'] += P_female == 0.5\n",
    "        \n",
    "        R['correct'] += (P_female > 0.5) if gender == 'F' else (P_female <= 0.5)\n",
    "        R['correct_w'] += P_female if gender == 'F' else (1-P_female)\n",
    "        \n",
    "        # R['conf'].append( P_female if gender == 'F' else (1 - P_female) )\n",
    "    \n",
    "    return R\n",
    "\n",
    "do_it(M.description, 'M', R)\n",
    "do_it(F.description, 'F', R)\n",
    "R['accuracy'] = R['correct'] / (len(M) + len(F))\n",
    "R"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "draws100% animates0% looœÄŒ¥ ggs\n",
      "correct=M guess=0.5 err=-0.5 username=itsuizzu\n",
      "------------------------------\n",
      "opposite opposite ela dela -\n",
      "correct=F guess=0.9996000800346002 err=0.00039991996539978647 username=InkedAmby\n",
      "------------------------------\n",
      "Ô∏è ‚Ä¢ ‚òºÔ∏é aÀ¢·∂ú\n",
      "correct=F guess=0.7002646373983767 err=0.29973536260162326 username=TsarAlek\n",
      "------------------------------\n",
      "mostly blm music stuff ‚Ä¢ acab ‚Ä¢ ‚Ä¢ lowkey trying to be an oasis fan account also among us professional player\n",
      "correct=M guess=0.14471099591901637 err=-0.14471099591901637 username=r0llwith1t\n",
      "------------------------------\n",
      "stray kids! stz - 96' liner to much love for those babies! fan account of @stray_kids portugues english\n",
      "correct=F guess=0.9970137157918624 err=0.002986284208137624 username=lecasp_\n",
      "------------------------------\n",
      "youtuber does edits occasionally casual creative player dying to have hotwire back main @winterdutchie\n",
      "correct=F guess=0.007776997201797848 err=0.9922230027982022 username=almondsnjoy\n",
      "------------------------------\n",
      "socialist antifascist queer disabled nerd who likes to sew #transrights i make cross stitch patterns\n",
      "correct=F guess=0.006893484631742676 err=0.9931065153682573 username=lukebway\n",
      "------------------------------\n",
      "history geek gin drinker assistant curator of archaeology @southendmuseums all views are mine retweets ‚â† endorsement ‚Äç\n",
      "correct=F guess=0.0017162477547838313 err=0.9982837522452161 username=thrognar\n",
      "------------------------------\n",
      "25 destiny & overwatch krogan swagmaster canuck blue jay panther raptor gladiator rooster tooth grump icon by @nkim_illustrate\n",
      "correct=M guess=0.06570364109605009 err=-0.06570364109605009 username=Jelmts\n",
      "------------------------------\n",
      "üÜÇüÜÉüÜÅüÖ¥üÖº ‚Äòon‚Äô cowards fan account dont s word me twt\n",
      "correct=F guess=0.9929056141085676 err=0.007094385891432409 username=typhon1996\n",
      "------------------------------\n",
      "professional movie enjoyer psu film video alum philadelphia free\n",
      "correct=M guess=0.01554897860491756 err=-0.01554897860491756 username=Billyjj98\n",
      "------------------------------\n",
      "middle aged trans woman #software #engineer #songwriter #sailor matrix @jvw #soundcloud https tco zhfpdmoold‚Ä¶\n",
      "correct=F guess=0.8281591677814959 err=0.1718408322185041 username=elephantbroFA\n",
      "------------------------------\n",
      "16!\n",
      "correct=F guess=0.5 err=0.5 username=Manikon14\n",
      "------------------------------\n",
      "aru 25 spends most of her time yelling about video games anime rt heavy not necessarily spoiler free\n",
      "correct=F guess=0.42968825193974103 err=0.570311748060259 username=MyNameIsSimon88\n",
      "------------------------------\n",
      "\"be good be good at it\" - @danielleri --\n",
      "correct=M guess=0.13296464313020745 err=-0.13296464313020745 username=Darkflight\n",
      "------------------------------\n",
      "you can‚Äôt hang with the big boys coming through with the big toys #haechan #mingi carrd byf\n",
      "correct=F guess=0.9676340417735271 err=0.032365958226472924 username=UnknownInGame\n",
      "------------------------------\n",
      "ùíüùí∂ùìåùìÉ ùìåùíæùìÅùìÅ ùí∏ùëúùìÇùëí ùìâùëú ùìâùíΩùëí ùíπùí∂ùìáùìÄùëíùìàùìâ ùëúùíª ùìÉùíæùëîùíΩùìâ\n",
      "correct=F guess=0.5 err=0.5 username=Nii_Kay75\n",
      "------------------------------\n",
      "author of poetry fantasy lest i know your weakness out now on amazon bn! instagram @ taylorrama\n",
      "correct=F guess=0.28283496622321797 err=0.7171650337767821 username=tonyothon\n",
      "------------------------------\n",
      "my name is dom hairy sad nerdy professionally shite #magicthegathering player\n",
      "correct=M guess=0.00592698641910102 err=-0.00592698641910102 username=sadbearnerd\n",
      "------------------------------\n",
      "#voiceactor musical theatre lover #dnd runner player accent fanatic coutokevinhome@gmailcom\n",
      "correct=M guess=0.010802077013838302 err=-0.010802077013838302 username=KCoutoVA\n",
      "------------------------------\n",
      "dl! former president of siue esports now i do stuff i like keyboards @bugcatcherwill\n",
      "correct=M guess=0.01049047589145715 err=-0.01049047589145715 username=TheDredgeLine\n",
      "------------------------------\n"
     ]
    }
   ],
   "source": [
    "# Show most confused\n",
    "\n",
    "import random\n",
    "\n",
    "\n",
    "f = random.sample(list(zip(M.username, F.description)), 100)\n",
    "m = random.sample(list(zip(M.username, M.description)), 100)\n",
    "\n",
    "shuff = [(*a,'F') for a in f] + [(*a,'M') for a in m]\n",
    "random.shuffle(shuff)\n",
    "\n",
    "errors = []\n",
    "\n",
    "for name, bio, gender in shuff:\n",
    "    t = tokenize(bio)\n",
    "    p = P_female_given(t)\n",
    "    error = (gender == 'F') - p\n",
    "    errors.append((name, t, gender, p, error))\n",
    "    \n",
    "\n",
    "i = 0\n",
    "for username, t, gender, p, error in errors: # sorted(errors, key=lambda x: x[-1]):\n",
    "    print(' '.join(t))\n",
    "    print(f'correct={gender} guess={p} err={error} username={username}')\n",
    "    print('-'*30)\n",
    "    i += 1\n",
    "    if i > 20:\n",
    "        break\n",
    "\n",
    "        \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "t = tokenize(\"AceüíúShe/Her/ Animator for Bento Box and a Character Designer that loves the weather and cute monsters ‚òÄÔ∏è üìß: achrosny@gmail.com ‚òÄÔ∏è Thoughts/Opinions are my own\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "t.lower().replace('she/her', '')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "t[20]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "P_female_given(['monsters'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "P_female_given([''])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "t[::-1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['well-rounded',\n",
       " 'geek',\n",
       " 'freelance',\n",
       " 'manga',\n",
       " 'adapter/rewriter',\n",
       " 'caretaker',\n",
       " 'of',\n",
       " '2',\n",
       " 'siberian',\n",
       " 'cats',\n",
       " 'current',\n",
       " 'fannish',\n",
       " 'love',\n",
       " 'ÈïáÈ≠Ç',\n",
       " '|',\n",
       " 'guardian',\n",
       " '(better',\n",
       " 'reflected',\n",
       " 'elsewhere',\n",
       " ')']"
      ]
     },
     "execution_count": 24,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "s = 'well-rounded geek freelance manga adapter/rewriter caretaker of 2 siberian cats current fannish love ÈïáÈ≠Ç | guardian (better reflected elsewhere )'\n",
    "t = tokenize(s)\n",
    "t"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 64,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.6975678459068225"
      ]
     },
     "execution_count": 64,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "P_female_given('football')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
